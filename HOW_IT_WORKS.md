# ğŸ¤” How Does the Chatbot Work? - Complete Explanation

## ğŸ—ï¸ Architecture Overview

You're running **3 separate services** that work together:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         USER OPENS http://localhost:5173                â”‚
â”‚              (React Frontend)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ User clicks chatbot button
                     â”‚ User types: "What companies visited?"
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   ChatBot.jsx         â”‚
         â”‚   (React Component)   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                    â”‚
           â–¼                    â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ZENITH RAG   â”‚    â”‚ MLR-Hack     â”‚
   â”‚ Backend      â”‚    â”‚ Node Backend â”‚
   â”‚ Port 8000    â”‚    â”‚ Port 5000    â”‚
   â”‚              â”‚    â”‚              â”‚
   â”‚ FOR CHATBOT  â”‚    â”‚ FOR OTHER    â”‚
   â”‚ ONLY         â”‚    â”‚ FEATURES     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Step-by-Step: What Happens When User Asks a Question

### Step 1: User Interaction
```
User opens: http://localhost:5173
â†’ Sees the MLR-Hack website (your teammates' design)
â†’ Clicks chatbot button (bottom-right corner)
â†’ Types: "What companies visited for placements?"
```

### Step 2: Frontend Processing (ChatBot.jsx)
**Location:** `mlr-hack/frontend/src/components/ChatBot.jsx`

```javascript
// When user sends message:
const userMessage = {
  text: "What companies visited for placements?"
};

// Build conversation history
const conversationHistory = [
  { role: "user", content: "previous questions..." },
  { role: "assistant", content: "previous answers..." },
  { role: "user", content: "What companies visited for placements?" }
];

// Send to Zenith RAG Backend
fetch('http://localhost:8000/api/v1/chat/', {
  method: 'POST',
  body: JSON.stringify({
    question: "What companies visited for placements?",
    conversation_history: conversationHistory
  })
});
```

**Why this happens:** The ChatBot component sends the question to YOUR Zenith backend, not the MLR-Hack backend!

### Step 3: Zenith RAG Backend Processing
**Location:** `mlr-hack/zenith-backend/` (Port 8000)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. REQUEST ARRIVES at /api/v1/chat/                 â”‚
â”‚     Question: "What companies visited?"              â”‚
â”‚     History: [...previous conversation...]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. EMBEDDING SERVICE                                â”‚
â”‚     Converts question to vector embedding            â”‚
â”‚     Uses: Cohere API                                 â”‚
â”‚     Output: [0.123, -0.456, 0.789, ...]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. VECTOR SEARCH IN PINECONE                        â”‚
â”‚     Searches Pinecone database for similar vectors   â”‚
â”‚     Finds: "placements_2024.pdf"                     â”‚
â”‚            "companies_list.csv"                      â”‚
â”‚            "google_interview.txt"                    â”‚
â”‚     Returns: Top 5 most relevant chunks              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. CONTEXT BUILDING                                 â”‚
â”‚     Combines:                                        â”‚
â”‚     â€¢ Retrieved documents from Pinecone              â”‚
â”‚     â€¢ Conversation history                           â”‚
â”‚     â€¢ User's current question                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. SEND TO GEMINI AI                                â”‚
â”‚     Model: gemini-1.5-flash-latest                   â”‚
â”‚     Prompt: "Based on this context: [documents]      â”‚
â”‚              And this history: [conversation]        â”‚
â”‚              Answer: What companies visited?"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. GEMINI GENERATES ANSWER                          â”‚
â”‚     "Based on the placement data, companies like     â”‚
â”‚      Google, Microsoft, Amazon, and TCS visited      â”‚
â”‚      MLRIT in 2024. Google offered packages up       â”‚
â”‚      to 45 LPA..."                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. RESPONSE SENT BACK TO FRONTEND                   â”‚
â”‚     {                                                â”‚
â”‚       "answer": "Based on the placement data...",    â”‚
â”‚       "sources": ["placements_2024.pdf"],            â”‚
â”‚       "images": [...],                               â”‚
â”‚       "category": "placements"                       â”‚
â”‚     }                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step 4: Frontend Displays Answer
```javascript
// ChatBot.jsx receives response
const botMessage = {
  text: data.answer,
  sources: data.sources,  // Shows which docs were used
  images: data.images,    // Any relevant images
  category: data.category // "placements"
};

// Displays in chat window with source citations
```

---

## ğŸ”€ Why 3 Terminals? What Does Each Do?

### Terminal 1: Zenith RAG Backend (Port 8000)
```powershell
cd d:\Projects\Zenith\mlr-hack\zenith-backend
uvicorn app.main:app --reload --port 8000
```

**Purpose:** Handles ONLY the chatbot
**Does:**
- âœ… Receives chat questions from frontend
- âœ… Searches Pinecone vector database
- âœ… Calls Gemini AI for intelligent answers
- âœ… Returns answers with sources
- âœ… Maintains conversation context

**Does NOT:**
- âŒ Handle exams, events, placements pages
- âŒ Handle user authentication
- âŒ Handle any other MLR-Hack features

### Terminal 2: MLR-Hack Node Backend (Port 5000)
```powershell
cd d:\Projects\Zenith\mlr-hack\backend
npm start
```

**Purpose:** Handles ALL other MLR-Hack features
**Does:**
- âœ… User login/authentication
- âœ… Exams API (`/api/exams`)
- âœ… Events API (`/api/events`)
- âœ… Placements data API (`/api/placements`)
- âœ… Student progress, clubs, analytics
- âœ… Database operations (MongoDB)

**Does NOT:**
- âŒ Handle chatbot messages (that's Zenith's job!)

### Terminal 3: Frontend (Port 5173)
```powershell
cd d:\Projects\Zenith\mlr-hack\frontend
npm run dev
```

**Purpose:** The user interface (what users see)
**Does:**
- âœ… Renders all pages (Home, Exams, Events, etc.)
- âœ… Shows chatbot button
- âœ… Sends chatbot questions to Port 8000 (Zenith)
- âœ… Sends other requests to Port 5000 (MLR-Hack)
- âœ… Displays responses to user

---

## ğŸ”„ Complete Flow Example

### Scenario 1: User Asks Chatbot Question
```
1. User types in chatbot: "What companies visited?"
   â†“
2. Frontend (5173) â†’ POST http://localhost:8000/api/v1/chat/
   â†“
3. Zenith Backend (8000) processes:
   - Searches Pinecone database
   - Calls Gemini AI
   - Generates intelligent answer
   â†“
4. Zenith Backend (8000) â†’ Returns JSON response
   â†“
5. Frontend (5173) displays answer in chatbot
```

### Scenario 2: User Views Exam Schedule
```
1. User clicks "Exams" page
   â†“
2. Frontend (5173) â†’ GET http://localhost:5000/api/exams
   â†“
3. MLR-Hack Backend (5000) queries MongoDB
   â†“
4. MLR-Hack Backend (5000) â†’ Returns exam data
   â†“
5. Frontend (5173) displays exam schedule
```

**Notice:** Different features use different backends!

---

## ğŸ¯ Why This Architecture?

### âœ… Advantages:

1. **Separation of Concerns**
   - Chatbot logic isolated in Zenith backend
   - MLR-Hack features in Node backend
   - Easy to maintain and debug

2. **Your Teammates' Work Preserved**
   - Their UI design unchanged
   - Their backend features still work
   - Only chatbot enhanced with RAG

3. **Scalability**
   - Can deploy Zenith backend separately
   - Can update chatbot without touching other features
   - Can scale each service independently

4. **Technology Freedom**
   - Python for AI/ML (Zenith backend)
   - Node.js for web services (MLR-Hack backend)
   - React for UI (Frontend)

### ğŸ”§ How They Connect:

```
Frontend knows:
- Chat questions â†’ http://localhost:8000/api/v1/chat/
- Everything else â†’ http://localhost:5000/api/...

ChatBot.jsx:
  apiEndpoint = 'http://localhost:8000/api/v1/chat/' â† Zenith

Other pages:
  VITE_API = 'http://localhost:5000' â† MLR-Hack
```

---

## ğŸ§  What is RAG? (Retrieval-Augmented Generation)

### Without RAG (Normal AI):
```
User: "What companies visited MLRIT?"
AI: "I don't have specific information about MLRIT."
```
âŒ AI doesn't know your specific data

### With RAG (Your Zenith Backend):
```
User: "What companies visited MLRIT?"
  â†“
1. Search Pinecone for "companies" + "MLRIT" + "visited"
2. Find documents: placements_2024.pdf, companies_list.csv
3. Send to Gemini: "Based on THIS data: [docs], answer the question"
  â†“
AI: "Based on the placement data, Google, Microsoft,
     Amazon, and TCS visited MLRIT in 2024..."
```
âœ… AI has context from YOUR documents!

---

## ğŸ“Š Data Flow Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   USER       â”‚
â”‚ (Browser)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend               â”‚
â”‚   localhost:5173         â”‚
â”‚                          â”‚
â”‚   â€¢ Shows UI             â”‚
â”‚   â€¢ Has ChatBot.jsx      â”‚
â”‚   â€¢ Routes requests      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚          â”‚
      â”‚          â”‚
      â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                             â”‚
      â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Zenith Backend  â”‚      â”‚ MLR-Hack Backendâ”‚
â”‚ localhost:8000  â”‚      â”‚ localhost:5000  â”‚
â”‚                 â”‚      â”‚                 â”‚
â”‚ â€¢ RAG Pipeline  â”‚      â”‚ â€¢ Exams API     â”‚
â”‚ â€¢ Pinecone DB   â”‚      â”‚ â€¢ Events API    â”‚
â”‚ â€¢ Gemini AI     â”‚      â”‚ â€¢ Auth          â”‚
â”‚ â€¢ CHATBOT ONLY  â”‚      â”‚ â€¢ MongoDB       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ‰ Summary

**3 Terminals = 3 Services:**

1. **Terminal 1 (Zenith - 8000):** Smart chatbot with RAG
2. **Terminal 2 (MLR-Hack - 5000):** All other features
3. **Terminal 3 (Frontend - 5173):** User interface

**When user asks chatbot:**
- Frontend â†’ Zenith Backend â†’ Pinecone â†’ Gemini â†’ Answer â†’ Frontend

**When user uses other features:**
- Frontend â†’ MLR-Hack Backend â†’ MongoDB â†’ Data â†’ Frontend

**Best of both worlds!** ğŸš€
- Your teammates' UI (unchanged)
- Your powerful RAG chatbot (enhanced)
- All working together seamlessly!

---

Now let me start the Zenith backend with the fixed PyMuPDF! ğŸ”§
